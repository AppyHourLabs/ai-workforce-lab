# Draft: Perplexity AI - EvalPal Introduction

**Status:** `draft: pending-review`  
**Created:** 2026-02-27 05:45 ET  
**Target:** Perplexity AI — Aravind Srinivas, Co-founder & CEO  
**Priority:** High (Tier 2 prospect, but high visibility / fast-moving)

## Email Draft

**To:** aravind@perplexity.ai [⚠️ UNVERIFIED — common pattern; verify before sending]  
**From:** matt@appyhourlabs.com  
**Subject:** How do you test factual accuracy at Perplexity's scale?

---

Hi Aravind,

Factual accuracy is basically your whole brand. Curious how your team tests for it beyond manual spot-checks — whether that's citation validation, answer drift across model updates, or edge cases where the retrieved context is right but the answer still goes sideways.

We built EvalPal to automate exactly that: systematic evals for LLM outputs before and after model changes. The kind of testing that tells you "this update broke answer quality in medical queries" before your users do.

Would love to see how it compares to what you're already running internally. 15 minutes?

Best,  
Matt  
Founder, Appy Hour Labs

---

## Quality Gate Check

✅ **Specific and relevant** — Leads with Perplexity's core value prop (factual accuracy)  
✅ **Human voice** — Opens with a genuine question, not a pitch  
✅ **Clear value proposition** — Catches accuracy regressions before users do  
✅ **Appropriate length** — 3 short paragraphs, tight  
✅ **Call to action** — 15-minute call  
✅ **Credibility** — Shows knowledge of their problem space (citation validation, model drift)

## Research Notes

- **Contact:** Aravind Srinivas, Co-founder & CEO — `aravind@perplexity.ai` [⚠️ UNVERIFIED]
- **Pain point:** Answer factual accuracy at scale; model updates can silently regress quality
- **Angle:** Frame around their brand promise — factual accuracy is their differentiator, any regression is existential
- **Timing:** Perplexity has been expanding aggressively; testing infrastructure tends to lag product velocity

## Next Steps

1. **Matt to verify contact** — LinkedIn or Perplexity team/about page
2. **Review and approve** — Matt reviews, edits if needed, sends manually
