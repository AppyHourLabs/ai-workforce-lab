# AI Workforce Lab

> **By Appy Hour Labs** Â· Public experiment in responsible AI deployment Â· Powered by **EvalPal**

---

What does it actually look like to deploy AI agents as persistent team members â€” with real governance, real failure modes, and a public paper trail of what happened?

That's what this repository answers. In real time. With the receipts committed.

---

## What We're Building

**EvalPal** is the product: tooling and methodology for evaluating AI agent quality in production workflows. The AI Workforce Lab is EvalPal's first test environment â€” we're building the eval harness by being the thing it evaluates.

**The experiment:** deploy AI agents into operational roles (documentation, QA, content, security, financial analysis, technical strategy, sales outreach, development, product) using a tiered autonomy model. Document everything. Ship the governance alongside the features.

**Current fleet:** 10 agents running on staggered daily cron schedules (03:45â€“08:00 ET), coordinated by a manager agent with shared brain memory.

**The constraint:** safety first. Always. If the choice is between moving fast and being safe, we choose safe and write a task about it.

---

## The Autonomy Model

| Phase | What it means |
|---|---|
| **Phase A** (current) | All outbound actions require human approval. Eval gates run before content approaches external recipients. Agents draft, analyze, propose â€” they do not send or publish autonomously. |
| **Phase B** (future) | Agents may publish within approved scope without per-action human review. Requires measurable evidence from Phase A. Criteria: [`POLICIES/phase-a-to-b.md`](POLICIES/phase-a-to-b.md) |

---

## Repository Map

```
ai-workforce-lab/
â”œâ”€â”€ AGENTS/          â† role definitions for each AI and human operator
â”œâ”€â”€ DOCS/SHOW/       â† public weekly episodes (the documentary)
â”‚   â””â”€â”€ episodes/
â”œâ”€â”€ EVALS/           â† quality gate rubrics and results
â”œâ”€â”€ POLICIES/        â† governance, safety, OAuth, posting, escalation rules
â”œâ”€â”€ PROJECTS/        â† strategic project definitions
â”œâ”€â”€ RUNBOOKS/        â† operational how-tos: CI, session handoff, incident response
â””â”€â”€ TASKS/           â† atomic execution tasks (30â€“60 min each)
```

---

## Key Policies

| Policy | What it covers |
|---|---|
| [AI Safety Charter](POLICIES/ai-safety-charter.md) | Non-negotiable principles |
| [OAuth Policy](POLICIES/oauth-policy.md) | Scope restrictions, no domain-wide delegation |
| [Posting Policy](POLICIES/posting-policy.md) | Who can publish, eval gate requirements |
| [Escalation Policy](POLICIES/escalation-policy.md) | Severity levels, when to ping the founder |
| [Phase A â†’ B Criteria](POLICIES/phase-a-to-b.md) | Measurable promotion gates |

---

## The Team

### Human Operators

| Account | Role |
|---|---|
| `matt@appyhourlabs.com` | Founder â€” final authority on all policy and autonomy decisions |
| `legal@appyhourlabs.com` | Legal review â€” no AI delegation |
| `security@appyhourlabs.com` | Credential and security management â€” human only |
| `billing@appyhourlabs.com` | Financial accounts â€” human only, no exceptions |

### AI Agent Fleet

| Agent | ID | Schedule | Role |
|---|---|---|---|
| ğŸ¯ Manager | `manager` | 03:45 ET | Fleet coordination, task routing, daily briefings |
| ğŸ¬ Documentary | `doc` | 04:00 ET | Episode drafting, repo scanning, PR creation |
| ğŸ” QA | `qa` | 04:30 ET | Quality gates, brand voice evaluation, PR review |
| âœï¸ Content | `content` | 05:00 ET | Social posts, blog drafts, content calendar |
| ğŸ›¡ï¸ Security | `security` | 05:30 ET | Security scans, policy checks, credential detection |
| ğŸ’° CFO | `cfo` | 06:00 ET | Budget modeling, cost tracking, token efficiency |
| ğŸ—ï¸ CTO | `cto` | 06:30 ET | ADRs, architecture, SDLC standards, CI/CD oversight |
| ğŸ“ SDR | `sdr` | 07:00 ET | Prospect research, outreach drafting, pipeline tracking |
| ğŸ’» Dev | `dev` | 07:30 ET | Full-stack development, testing, PR authoring |
| ğŸ¨ Product | `product` | 08:00 ET | Product strategy, backlog refinement, sprint planning |

Full role specs: [`AGENTS/`](AGENTS/)

---

## The Show

Every week, `doc@appyhourlabs.com` files an episode documenting what shipped, what broke, what was decided, and what we learned. Public, honest, occasionally funny.

- [Episode 000 â€” Origin Log](DOCS/SHOW/episodes/000-origin-log.md)
- [Episode 001 â€” The AI Office Moves In](DOCS/SHOW/episodes/001-ai-office-moves-in.md)
- [Episode 002 â€” The First Agent Goes Live](DOCS/SHOW/episodes/002-the-first-agent-goes-live.md)
- [Episode 003 â€” Agent Wires Itself](DOCS/SHOW/episodes/003-agent-wires-itself.md)
- [Episode template](<DOCS/SHOW/episodes/_TEMPLATE.md>)

---

## Status

*Last updated: 2026-02-22*

| Project | Status | What it is |
|---|---|---|
| [0001 â€” Google Workspace Hardening](PROJECTS/0001-google-workspace-hardening.md) | ğŸ”µ Active | MFA, API access controls, OAuth scope audit for all AI ops accounts |
| [0002 â€” Mac Mini AI Office Setup](PROJECTS/0002-mac-mini-ai-office-setup.md) | ğŸ”µ Active | Dedicated hardened machine for running agent pipelines |

Autonomy tier: **Phase A** â€” all outbound requires human approval.

Fleet: **10 agents** across 7 functions (documentation, quality, content, security, finance, engineering, sales, development, product). CampClaw Steps 00â€“12 complete.

---

## Start Here

New here? Read in this order:

1. [Episode 000 â€” Origin Log](DOCS/SHOW/episodes/000-origin-log.md) â€” why this project exists
2. [Episode 001 â€” The AI Office Moves In](DOCS/SHOW/episodes/001-ai-office-moves-in.md) â€” what we did first and why
3. [AI Safety Charter](POLICIES/ai-safety-charter.md) â€” the non-negotiables
4. [`AGENTS.md`](AGENTS.md) â€” who does what (human and AI)

---

## Safety

This project operates under a formal safety charter. The short version:

- No agent acts autonomously on external communications in Phase A
- No secrets, credentials, or PII in this repository â€” ever
- All agent scope changes require human sign-off
- Every incident gets logged; nothing gets quietly swept

Full details: [`POLICIES/ai-safety-charter.md`](POLICIES/ai-safety-charter.md)

---

## How to Follow

- **Watch this repo** â€” GitHub â†’ Watch â†’ "All Activity" for commits, PRs, and issues
- **Star it** â€” helps others find the experiment
- **Read the episodes** â€” [`DOCS/SHOW/episodes/`](DOCS/SHOW/episodes/) is updated weekly by `doc@appyhourlabs.com`
- **Open an issue** â€” questions, observations, or suggested tasks are welcome using the [task template](.github/ISSUE_TEMPLATE/task.md)

No mailing list, no newsletter, no algorithm. Just commits.

---

## Contributing

1. Read [`POLICIES/ai-safety-charter.md`](POLICIES/ai-safety-charter.md) first
2. Select a task from [`TASKS/`](TASKS/) or a project from [`PROJECTS/`](PROJECTS/)
3. Small PRs. Every PR needs a **Security Considerations** section
4. No secrets, no PII, ISO dates only

See [`AGENTS.md`](AGENTS.md) for the full contributor context guide.

---

## License

[MIT](LICENSE) â€” use freely, cite honestly.
